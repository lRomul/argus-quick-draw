{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import argus\n",
    "from argus import Model\n",
    "from argus.callbacks import MonitorCheckpoint, EarlyStopping\n",
    "from argus.callbacks import LoggingToFile, ReduceLROnPlateau\n",
    "\n",
    "from src.datasets import DrawDataset, get_train_val_samples\n",
    "from src.transforms import ImageTransform, DrawTransform\n",
    "from src.argus_models import CnnFinetune\n",
    "from src.metrics import MAPatK\n",
    "from src import config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, figsize=(3, 3)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "scale_size = 64\n",
    "random_crop_size = (120, 128)\n",
    "rotate_angle = 15\n",
    "max_border_scale = 0.7\n",
    "image_pad = 4\n",
    "image_line_width = 2\n",
    "time_color = False\n",
    "train_batch_size = 2048\n",
    "val_batch_size = 2048\n",
    "train_epoch_size = 1000000\n",
    "val_key_id_path = '/workdir/data/val_key_ids_001.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, val_samples = get_train_val_samples(val_key_id_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_transform = DrawTransform(image_size, image_pad, image_line_width, time_color)\n",
    "train_trns = ImageTransform(True, scale_size, random_crop_size, rotate_angle, max_border_scale)\n",
    "train_dataset = DrawDataset(train_samples, draw_transform,\n",
    "                            size=train_epoch_size, image_transform=train_trns)\n",
    "val_trns = ImageTransform(False)\n",
    "val_dataset = DrawDataset(val_samples, draw_transform, image_transform=val_trns)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, num_workers=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=val_batch_size, num_workers=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images_to_draw = 3\n",
    "\n",
    "for img, trg in train_loader:\n",
    "    for i in range(n_images_to_draw):\n",
    "        img_i = img[i, 0, :, :].numpy()\n",
    "        print(config.IDX_TO_CLASS[trg[i].item()])\n",
    "        imshow(img_i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'nn_module': {\n",
    "        'model_name': 'resnet34',\n",
    "        'num_classes': len(config.CLASSES),\n",
    "        'pretrained': True,\n",
    "        'dropout_p': 0.5\n",
    "    },\n",
    "    'optimizer': ('Adam', {'lr': 0.001}),\n",
    "    'loss': 'CrossEntropyLoss',\n",
    "    'device': 'cuda'\n",
    "}\n",
    "\n",
    "model = CnnFinetune(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment_name = 'cnn_fine_resnet34_006'\n",
    "\n",
    "callbacks = [\n",
    "    MonitorCheckpoint(f'/workdir/data/experiments/{experiment_name}', monitor='val_map_at_k', max_saves=3),\n",
    "    EarlyStopping(monitor='val_map_at_k', patience=50),\n",
    "    ReduceLROnPlateau(monitor='val_map_at_k', factor=0.64, patience=5, min_lr=0.00001),\n",
    "    LoggingToFile(f'/workdir/data/experiments/{experiment_name}/log.txt')\n",
    "]\n",
    "\n",
    "model.fit(train_loader, \n",
    "          val_loader=val_loader,\n",
    "          max_epochs=1000,\n",
    "          callbacks=callbacks,\n",
    "          metrics=['accuracy', MAPatK(k=3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self, model_path, draw_transform, image_transform):\n",
    "        self.model = load_model(model_path)\n",
    "        self.model.nn_module.eval()\n",
    "\n",
    "        self.draw_transform = draw_transform\n",
    "        self.image_transform = image_transform\n",
    "\n",
    "    def __call__(self, drawings):\n",
    "        tensors = []\n",
    "        for drawing in drawings:\n",
    "            image = self.draw_transform(drawing)\n",
    "            tensor = self.image_transform(image)\n",
    "            tensors.append(tensor)\n",
    "        \n",
    "        tensor = torch.stack(tensors, dim=0)\n",
    "        tensor = tensor.to(self.model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            probs = self.model.predict(tensor)\n",
    "            return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src import config\n",
    "import tqdm\n",
    "\n",
    "from argus import load_model\n",
    "\n",
    "pred_batch_size = 1024 \n",
    "model_path = '/workdir/data/experiments/cnn_fine_se_resnext50_004/model-097-0.814777.pth'\n",
    "\n",
    "test_df = pd.read_csv(config.TEST_SIMPLIFIED_PATH)\n",
    "sample_subm = pd.read_csv(config.SAMPLE_SUBMISSION)\n",
    "predictor = Predictor(model_path, draw_transform, val_trns)\n",
    "\n",
    "drawings = []\n",
    "key_ids = []\n",
    "pred_words = []\n",
    "pred_key_ids = []\n",
    "for i, row in tqdm.tqdm(test_df.iterrows()):\n",
    "    drawing = eval(row.drawing)\n",
    "    \n",
    "    drawings.append(drawing)\n",
    "    key_ids.append(row.key_id)\n",
    "    if len(drawings) == pred_batch_size:\n",
    "        probs = predictor(drawings).cpu().numpy()\n",
    "        preds_idx = probs.argsort(axis=1)\n",
    "        preds_idx = np.fliplr(preds_idx)[:, :3]\n",
    "        for pred_idx, key_id in zip(preds_idx, key_ids):\n",
    "            words = [config.IDX_TO_CLASS[i].replace(' ', '_') for i in pred_idx]\n",
    "            pred_words.append(\" \".join(words))\n",
    "            pred_key_ids.append(key_id)\n",
    "            \n",
    "        drawings = []\n",
    "        key_ids = []\n",
    "        \n",
    "probs = predictor(drawings).cpu().numpy()\n",
    "preds_idx = probs.argsort(axis=1)\n",
    "preds_idx = np.fliplr(preds_idx)[:, :3]\n",
    "for pred_idx, key_id in zip(preds_idx, key_ids):\n",
    "    words = [config.IDX_TO_CLASS[i].replace(' ', '_') for i in pred_idx]\n",
    "    pred_words.append(\" \".join(words))\n",
    "    pred_key_ids.append(key_id)\n",
    "\n",
    "drawings = []\n",
    "key_ids = []\n",
    "    \n",
    "subm = pd.DataFrame({'key_id': pred_key_ids, 'word': pred_words})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.to_csv('/workdir/data/first_subm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
